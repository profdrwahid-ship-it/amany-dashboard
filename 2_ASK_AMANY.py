# ğŸ“„ pages/2_ASK_AMANY.py (Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© ÙˆØ§Ù„Ù…Ø³ØªÙ‚Ù„Ø©)

import streamlit as st
import pandas as pd
import os
import google.generativeai as genai

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ---
st.set_page_config(page_title="AMANY - Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ", layout="wide", page_icon="ğŸ§ ")

# --- Ø§Ø³ØªØ§ÙŠÙ„ CSS ---
st.markdown("""
    <style>
    /* ... Ù†ÙØ³ ÙƒÙˆØ¯ Ø§Ù„Ù€ CSS Ø§Ù„Ø³Ø§Ø¨Ù‚ ... */
    .amany-header { background: #14389f; padding: 0.7em 0; box-shadow: 0 2px 8px #c2cbe5; text-align: center; color: white; margin-bottom: 1.5rem; }
    .amany-header-title { font-size: 2.2em; font-weight: bold; background: linear-gradient(90deg,#06dc95,#36e5ff,#33d1ff 80%); -webkit-background-clip: text; -webkit-text-fill-color: transparent; letter-spacing: 7px; margin: 0; }
    .amany-header-sub { color: #fff; font-size: 1.2em; margin-top: 0.1em; }
    .amany-abbreviation { color: #e3f6ff; font-size: 1em; font-weight: bold; letter-spacing: 2px; margin-top: 0.5em; }
    .main-title { font-size: 1.35em; font-weight: bold; color: #1976d2; letter-spacing: 2px; margin-bottom: 0.3em; text-align: center;}
    .stChatMessage .stMarkdown p { font-size: 1.15rem; line-height: 1.6; }
    </style>
""", unsafe_allow_html=True)

# --- Ø§Ù„Ù‡ÙŠØ¯Ø± ---
st.markdown("""
    <div class="amany-header">
        <div class="amany-header-title">AMANY</div>
        <div class="amany-header-sub">Ø§Ù„Ù‡ÙŠØ¦Ø© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù„Ø±Ø¹Ø§ÙŠØ© Ø§Ù„ØµØ­ÙŠØ© - Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø±Ø¹Ø§ÙŠØ© Ø§Ù„Ø£ÙˆÙ„ÙŠØ© ÙØ±Ø¹ Ø¬Ù†ÙˆØ¨ Ø³ÙŠÙ†Ø§Ø¡</div>
        <div class="amany-abbreviation">Advanced Medical Analytics Networking Yielding</div>
    </div>
""", unsafe_allow_html=True)

st.title("ğŸ§  Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ ASK AMANY")
st.write("Ù‡Ø°Ù‡ Ø§Ù„ØµÙØ­Ø© ØªØªÙŠØ­ Ù„Ùƒ Ø·Ø±Ø­ Ø£Ø³Ø¦Ù„Ø© Ù…Ø¨Ø§Ø´Ø±Ø© Ø­ÙˆÙ„ Ø£ÙŠ Ù…Ù„Ù Ø¨ÙŠØ§Ù†Ø§Øª Ù„ÙŠÙ‚ÙˆÙ… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¨ØªØ­Ù„ÙŠÙ„Ù‡ ÙˆØ§Ù„Ø¥Ø¬Ø§Ø¨Ø©.")

# --- Ø¯Ø§Ù„Ø© Ù„Ø¬Ù„Ø¨ Ø§Ù„Ù…Ù„ÙØ§Øª Ù…Ù† Ø¹Ø¯Ø© Ù…Ø¬Ù„Ø¯Ø§Øª ---
@st.cache_data
def get_all_files_from_folders(folders):
    all_files = []
    for folder in folders:
        if not os.path.exists(folder):
            os.makedirs(folder)
        files_in_folder = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith(".xlsx") and not f.startswith("~$")]
        all_files.extend(files_in_folder)
    return all_files

# --- Ø¬Ù„Ø¨ Ø§Ù„Ù…Ù„ÙØ§Øª Ù…Ù† Ù…Ø¬Ù„Ø¯ÙŠ uploads Ùˆ Center ---
FOLDERS_TO_SCAN = ["uploads", "Center"]
all_available_files = get_all_files_from_folders(FOLDERS_TO_SCAN)

if not all_available_files:
    st.error("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ù…Ù„ÙØ§Øª Ø¥ÙƒØ³Ù„ ÙÙŠ Ù…Ø¬Ù„Ø¯ÙŠ 'uploads' Ø£Ùˆ 'Center'.")
    st.stop()

# --- Ø£Ø¯ÙˆØ§Øª Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…Ù„ÙØ§Øª ÙÙŠ Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ ---
st.sidebar.header("Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ù„Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ")
file_path_to_analyze = st.sidebar.selectbox("1. Ø§Ø®ØªØ± Ù…Ù„ÙÙ‹Ø§ Ù„ØªØ­Ù„ÙŠÙ„Ù‡:", all_available_files, key="ai_file_selector")
sheet_to_analyze = st.sidebar.selectbox("2. Ø§Ø®ØªØ± ÙˆØ±Ù‚Ø© Ø§Ù„Ø¹Ù…Ù„:", pd.ExcelFile(file_path_to_analyze).sheet_names, key="ai_sheet_selector")

st.info(f"Ø¬Ø§Ù‡Ø² Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„Ù: **{os.path.basename(file_path_to_analyze)}** (ÙˆØ±Ù‚Ø©: **{sheet_to_analyze}**)")
st.markdown("---")

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª API ÙˆØ§Ù„Ù†Ù…ÙˆØ°Ø¬ ---
try:
    api_key = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel('gemini-1.5-flash')
except (KeyError, FileNotFoundError):
    st.error("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ÙØªØ§Ø­ GOOGLE_API_KEY.")
    st.stop()
except Exception as e:
    st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆØ°Ø¬ Google AI: {e}")
    st.stop()

# --- Ù…Ù†Ø·Ù‚ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© ---
chat_key = f"chat_history_{file_path_to_analyze}_{sheet_to_analyze}"
if chat_key not in st.session_state:
    st.session_state[chat_key] = []

@st.cache_data(ttl=3600)
def get_data_context(_file_path, _sheet):
    try:
        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù Ù…Ø¹ Ø§ÙØªØ±Ø§Ø¶ Ø£Ù† Ø§Ù„ØµÙ Ø§Ù„Ø£ÙˆÙ„ Ù‡Ùˆ Ø§Ù„Ù‡ÙŠØ¯Ø± (header=0)
        df_context = pd.read_excel(_file_path, sheet_name=_sheet, header=0)
        context_text = f"Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù: {os.path.basename(_file_path)}\nØ§Ø³Ù… Ø§Ù„ÙˆØ±Ù‚Ø©: {_sheet}\n\n{df_context.to_string()}"
        return context_text
    except Exception as e:
        return f"Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù: {e}"

# Ø¹Ø±Ø¶ Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
for message in st.session_state[chat_key]:
    with st.chat_message(message["role"]):
        st.markdown(message["text"])

# Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
if prompt := st.chat_input("Ø§Ø³Ø£Ù„ Ø¹Ù† Ø¨ÙŠØ§Ù†Ø§ØªÙƒ..."):
    st.session_state[chat_key].append({"role": "user", "text": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("... ÙŠÙÙƒØ± ASK AMANY"):
            data_context = get_data_context(file_path_to_analyze, sheet_to_analyze)
            full_prompt = f"""Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ø§Ø³Ù…Ù‡ "ASK AMANY". Ø­Ù„Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© ÙˆØ£Ø¬Ø¨ Ø¹Ù† Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…. Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: --- {data_context} --- Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: "{prompt}" """
            try:
                response = model.generate_content(full_prompt)
                response_text = response.text
                st.markdown(response_text)
                st.session_state[chat_key].append({"role": "assistant", "text": response_text})
            except Exception as e:
                st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø§Ù„Ù€ API: {e}")
